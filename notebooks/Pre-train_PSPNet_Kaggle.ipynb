{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c83259",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "%cd /kaggle/working\n",
    "\n",
    "\n",
    "repo_name = \"benchmarking-generative-models-for-domain-adaptation\"\n",
    "if os.path.exists(repo_name):\n",
    "    shutil.rmtree(repo_name)\n",
    "\n",
    "\n",
    "print(\"Clono la repository...\")\n",
    "!git clone --recursive https://github.com/AntonioRosano/benchmarking-generative-models-for-domain-adaptation.git\n",
    "%cd {repo_name}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b38e8ed",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%cd /kaggle/working/benchmarking-generative-models-for-domain-adaptation/models/pspnet\n",
    "\n",
    "os.makedirs('initmodel', exist_ok=True)\n",
    "\n",
    "\n",
    "source_path = \"/kaggle/input/resnet50-weights/resnet50_v2.pth\" \n",
    "destination_path = \"./initmodel/resnet50_v2.pth\"\n",
    "\n",
    "\n",
    "if os.path.exists(source_path):\n",
    "    shutil.copy(source_path, destination_path)\n",
    "    print(f\"Pesi copiati con successo in: {destination_path}\")\n",
    "else:\n",
    "    print(f\"Errore: Non trovo il file in {source_path}\")\n",
    "    print(\"File disponibili in input:\")\n",
    "    for root, dirs, files in os.walk(\"/kaggle/input\"):\n",
    "        for file in files:\n",
    "            print(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d3d392",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "dataset_root = \"/kaggle/input/datasets/antoniorosano/ego-ch/EGO-CH-OBJ-SEG/synthetic/train\"\n",
    "img_dir = os.path.join(dataset_root, \"frames\")\n",
    "mask_dir = os.path.join(dataset_root, \"labels\")\n",
    "\n",
    "output_folder = \"/kaggle/working/benchmarking-generative-models-for-domain-adaptation/models/pspnet/lists/ego_ch\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "print(f\"Scansiono le cartelle:\\n   IMG: {img_dir}\\n   MSK: {mask_dir}\")\n",
    "\n",
    "\n",
    "images_dict = {\n",
    "    os.path.splitext(f)[0]: os.path.join(img_dir, f) \n",
    "    for f in os.listdir(img_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
    "}\n",
    "\n",
    "masks_dict = {\n",
    "    os.path.splitext(f)[0]: os.path.join(mask_dir, f) \n",
    "    for f in os.listdir(mask_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
    "}\n",
    "\n",
    "print(f\"\\nStatistiche grezze:\")\n",
    "print(f\"   Immagini trovate: {len(images_dict)}\")\n",
    "print(f\"   Labels trovate:   {len(masks_dict)}\")\n",
    "\n",
    "# --- RISOLUZIONE BUG (INTERSEZIONE) ---\n",
    "# Troviamo solo i nomi presenti in ENTRAMBE le liste\n",
    "common_names = list(set(images_dict.keys()) & set(masks_dict.keys()))\n",
    "print(f\"\\nCoppie valide (MATCH): {len(common_names)}\")\n",
    "print(f\"File scartati (senza coppia): {len(images_dict) + len(masks_dict) - 2*len(common_names)}\")\n",
    "\n",
    "# --- SPLIT TRAIN / VAL ---\n",
    "# Mescoliamo per evitare bias (es. se le immagini sono ordinate)\n",
    "random.seed(42)\n",
    "random.shuffle(common_names)\n",
    "\n",
    "# Usiamo il 90% per training e il 10% per validation\n",
    "split_idx = int(len(common_names) * 0.9)\n",
    "train_names = common_names[:split_idx]\n",
    "val_names = common_names[split_idx:]\n",
    "\n",
    "\n",
    "def write_list(names, filename):\n",
    "    path = os.path.join(output_folder, filename)\n",
    "    with open(path, \"w\") as f:\n",
    "        for name in names:\n",
    "            f.write(f\"{images_dict[name]} {masks_dict[name]}\\n\")\n",
    "    print(f\"Creato: {path} ({len(names)} righe)\")\n",
    "\n",
    "write_list(train_names, \"train.txt\")\n",
    "write_list(val_names, \"val.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079282f8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%cd /kaggle/working/benchmarking-generative-models-for-domain-adaptation/models/pspnet\n",
    "\n",
    "\n",
    "config_dir = \"config/ego_ch\"\n",
    "os.makedirs(config_dir, exist_ok=True)\n",
    "\n",
    "# YAML parametri del PAPER (LR=0.005, Epochs=30, ecc.)\n",
    "config_content = \"\"\"\n",
    "DATA:\n",
    "  data_root: /\n",
    "  train_list: /kaggle/working/benchmarking-generative-models-for-domain-adaptation/models/pspnet/lists/ego_ch/train.txt\n",
    "  val_list: /kaggle/working/benchmarking-generative-models-for-domain-adaptation/models/pspnet/lists/ego_ch/val.txt\n",
    "  classes: 25  # 24 opere + 1 sfondo (Verifica se le tue label sono 0-24 o 0-23)\n",
    "\n",
    "TRAIN:\n",
    "  arch: psp\n",
    "  layers: 50\n",
    "  sync_bn: False       \n",
    "  train_h: 473         # Crop\n",
    "  train_w: 473\n",
    "  scale_min: 0.5\n",
    "  scale_max: 2.0\n",
    "  rotate_min: -10\n",
    "  rotate_max: 10\n",
    "  zoom_factor: 8\n",
    "  ignore_label: 255\n",
    "  aux_weight: 0.4\n",
    "  train_gpu: [0]\n",
    "  workers: 2           \n",
    "  batch_size: 4\n",
    "  batch_size_val: 4\n",
    "  base_lr: 0.005       # Parametro dal PAPER\n",
    "  epochs: 30           # Parametro dal PAPER\n",
    "  start_epoch: 0\n",
    "  power: 0.9           # Parametro dal PAPER\n",
    "  momentum: 0.9        # Parametro dal PAPER\n",
    "  weight_decay: 0.0001 # Parametro dal PAPER\n",
    "  manual_seed: 0\n",
    "  print_freq: 10\n",
    "  save_freq: 1\n",
    "  save_path: exp/ego_ch/pspnet50/model\n",
    "  weight: initmodel/resnet50_v2.pth  # Il file che abbiamo sistemato prima\n",
    "  resume: \n",
    "  evaluate: True\n",
    "\n",
    "Distributed:\n",
    "  dist_url: tcp://127.0.0.1:6789\n",
    "  dist_backend: 'nccl'\n",
    "  multiprocessing_distributed: False\n",
    "  world_size: 1\n",
    "  rank: 0\n",
    "  use_apex: False\n",
    "  opt_level: 'O0'\n",
    "  keep_batchnorm_fp32: None\n",
    "  loss_scale: None\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "config_path = os.path.join(config_dir, \"pspnet50.yaml\")\n",
    "with open(config_path, \"w\") as f:\n",
    "    f.write(config_content)\n",
    "\n",
    "print(f\"Configurazione creata in: {config_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39858187",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(\"Risoluzione bug PSPNet noti...\")\n",
    "\n",
    "# --- 1. PATCH TRAIN.PY (Gestione Pesi) ---\n",
    "train_path = \"/kaggle/working/benchmarking-generative-models-for-domain-adaptation/models/pspnet/tool/train.py\"\n",
    "if os.path.exists(train_path):\n",
    "    with open(train_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    new_lines = []\n",
    "    target = \"model.load_state_dict(checkpoint['state_dict'])\"\n",
    "    for line in lines:\n",
    "        if target in line:\n",
    "            indent = line[:line.find(\"model\")]\n",
    "            new_lines.extend([\n",
    "                f\"{indent}# --- PATCH APPLICATA: Supporto per pesi raw ---\\n\",\n",
    "                f\"{indent}if isinstance(checkpoint, dict) and 'state_dict' in checkpoint:\\n\",\n",
    "                f\"{indent}    model.load_state_dict(checkpoint['state_dict'], strict=False)\\n\",\n",
    "                f\"{indent}else:\\n\",\n",
    "                f\"{indent}    print('=> Key state_dict not found, loading raw weights...')\\n\",\n",
    "                f\"{indent}    model.load_state_dict(checkpoint, strict=False)\\n\"\n",
    "            ])\n",
    "        else:\n",
    "            new_lines.append(line)\n",
    "    with open(train_path, 'w') as f:\n",
    "        f.writelines(new_lines)\n",
    "    print(\"Patch train.py applicata.\")\n",
    "\n",
    "# --- 2. PATCH TRANSFORM.PY (Compatibilità Python 3.10+) ---\n",
    "trans_path = \"/kaggle/working/benchmarking-generative-models-for-domain-adaptation/models/pspnet/util/transform.py\"\n",
    "if os.path.exists(trans_path):\n",
    "    with open(trans_path, \"r\") as f:\n",
    "        content = f.read()\n",
    "    if \"collections.Iterable\" in content:\n",
    "        with open(trans_path, \"w\") as f:\n",
    "            f.write(content.replace(\"collections.Iterable\", \"collections.abc.Iterable\"))\n",
    "        print(\"Patch transform.py applicata (Iterable fix).\")\n",
    "\n",
    "# --- 3. REWRITE DATASET.PY (Sanitizzazione Maschere) ---\n",
    "dataset_code = \"\"\"\n",
    "import os\n",
    "import os.path\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "def make_dataset(split='train', data_root=None, data_list=None):\n",
    "    image_label_list = []\n",
    "    list_read = open(data_list).readlines()\n",
    "    for line in list_read:\n",
    "        line = line.strip().split(' ')\n",
    "        if split == 'test':\n",
    "            image_label_list.append(os.path.join(data_root, line[0]))\n",
    "        else:\n",
    "            image_label_list.append((os.path.join(data_root, line[0]), os.path.join(data_root, line[1])))\n",
    "    return image_label_list\n",
    "\n",
    "class SemData(Dataset):\n",
    "    def __init__(self, split='train', data_root=None, data_list=None, transform=None):\n",
    "        self.split = split\n",
    "        self.data_list = make_dataset(split, data_root, data_list)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path, label_path = self.data_list[index]\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = np.float32(image)\n",
    "        # Forza grayscale e sanitizza per evitare crash CUDA\n",
    "        label = cv2.imread(label_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if label.ndim == 3: label = label[:, :, 0]\n",
    "        # Tutto ciò che eccede le classi (es. 25) diventa 255 (ignore)\n",
    "        bad_pixels = (label >= 25) & (label != 255)\n",
    "        if np.any(bad_pixels): label[bad_pixels] = 255\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image, label = self.transform(image, label)\n",
    "        return image, label\n",
    "\"\"\"\n",
    "dataset_path = \"/kaggle/working/benchmarking-generative-models-for-domain-adaptation/models/pspnet/util/dataset.py\"\n",
    "with open(dataset_path, \"w\") as f:\n",
    "    f.write(dataset_code)\n",
    "print(\"Patch dataset.py applicata (Mask sanitizer).\")\n",
    "\n",
    "print(\"\\nTUTTE LE FIX SONO STATE APPLICATE. Il sistema è pronto per il training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1283bd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%cd /kaggle/working/benchmarking-generative-models-for-domain-adaptation/models/pspnet\n",
    "\n",
    "import sys\n",
    "import os\n",
    "os.environ['PYTHONPATH'] = os.getcwd()\n",
    "\n",
    "!pip install tensorboardX\n",
    "!python tool/train.py --config config/ego_ch/pspnet50.yaml"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
